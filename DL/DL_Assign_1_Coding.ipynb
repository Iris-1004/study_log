{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oswfDMQI1tBA"
   },
   "source": [
    "This problem involves writing several concise functions. The primary objective is to acquaint yourself with Python.\n",
    "\n",
    "**Avoid using external libraries such as numpy.** Stick to standard Python libraries or those already imported in the starter code.\n",
    "\n",
    "Write Python code to implement the functions specified in this ipynb file. Aim for clarity and simplicity in your code, ensuring to encapsulate your solutions between the \"begin answer\" and \"end answer\" comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iLhtX07o0wKY"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "from typing import Any, DefaultDict, List, Set, Tuple\n",
    "\n",
    "############################################################\n",
    "# Custom Types\n",
    "# NOTE: No modifications are necessary for the following description.\n",
    "\"\"\"\n",
    "The keys of the defaultdict can be conceptualized as representing positions\n",
    "within the sparse vector, while the corresponding values represent the elements\n",
    "at those positions. Absence of a key implies absence of the corresponding\n",
    "element in the sparse vector (i.e., it is zero). It's important to note that\n",
    "the type of keys used should not impact the algorithm. You can envision\n",
    "the keys as integer indices (e.g., 0, 1, 2) within the sparse vectors,\n",
    "but the algorithm should function identically with arbitrary keys\n",
    "(e.g., \"red\", \"blue\", \"green\").\n",
    "\"\"\"\n",
    "SparseVector = DefaultDict[Any, float]\n",
    "Position = Tuple[int, int]\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECYqsrlr5IAM"
   },
   "source": [
    "Problem 3-1. Implement *get_first_alphabetical_word*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ri2TQvON3lnd"
   },
   "outputs": [],
   "source": [
    "def get_first_alphabetical_word(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Given a string |text|, return the word in |text| that comes first\n",
    "    lexicographically (i.e., the word that would come first after sorting).\n",
    "    A word is defined by a maximal sequence of characters without whitespaces.\n",
    "    You might find min() handy here. If the input text is an empty string,\n",
    "    it is acceptable to either return an empty string or throw an error.\n",
    "    \"\"\"\n",
    "    # BEGIN_YOUR_CODE (our solution is 1 line of code, but don't worry if you deviate from this)\n",
    "\n",
    "        return min(text.split()) if text.strip() else \"\"\n",
    "    \n",
    "    raise Exception(\"Not implemented yet\")\n",
    "    # END_YOUR_CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7Qm3Jof68ye"
   },
   "source": [
    "Problem 3-2. Implement *get_euclidean_dist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ve7YSJpD69ct"
   },
   "outputs": [],
   "source": [
    "def get_euclidean_dist(loc1: Position, loc2: Position) -> float:\n",
    "    \"\"\"\n",
    "    Return the Euclidean distance between two locations, where the locations\n",
    "    are pairs of numbers (e.g., (2, 8)).\n",
    "    \"\"\"\n",
    "    # BEGIN_YOUR_CODE (our solution is 1 line of code, but don't worry if you deviate from this)\n",
    "    raise Exception(\"Not implemented yet\")\n",
    "    # END_YOUR_CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPWsC1xX7t2h"
   },
   "source": [
    "Probmel 3-3. Implement *cosine_similarity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "StsmbVAU7uHC"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1: List[float], vector2: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two vectors.\n",
    "    Cosine similarity measures the cosine of the angle between two vectors in n-dimensional space.\n",
    "    It is defined as the dot product of the vectors divided by the product of their magnitudes.\n",
    "    Args:\n",
    "        vector1: A list representing the first vector.\n",
    "        vector2: A list representing the second vector.\n",
    "    Returns:\n",
    "        The cosine similarity between the two input vectors.\n",
    "    Example:\n",
    "        vector1 = [1, 2, 3]\n",
    "        vector2 = [4, 5, 6]\n",
    "        cosine_similarity(vector1, vector2) returns approximately 0.97463\n",
    "    \"\"\"\n",
    "    # BEGIN_YOUR_CODE (our solution is 3 lines of code, but don't worry if you deviate from this)\n",
    "    raise Exception(\"Not implemented yet\")\n",
    "    # END_YOUR_CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiX0BxDs_oTs"
   },
   "source": [
    "Problem 3-4. Implement *sparse_vector_dot_product*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "MDqSKNlR_onA"
   },
   "outputs": [],
   "source": [
    "def sparse_vector_dot_product(v1: SparseVector, v2: SparseVector) -> float:\n",
    "    \"\"\"\n",
    "    Given two sparse vectors (vectors where most of the elements are zeros)\n",
    "    |v1| and |v2|, each represented as collections.defaultdict(float), return\n",
    "    their dot product.\n",
    "\n",
    "    You might find it useful to use sum() and a list comprehension.\n",
    "    This function will be useful later for linear classifiers.\n",
    "    Note: A sparse vector has most of its entries as 0.\n",
    "    \"\"\"\n",
    "    # BEGIN_YOUR_CODE (our solution is 1 line of code, but don't worry if you deviate from this)\n",
    "    raise Exception(\"Not implemented yet\")\n",
    "    # END_YOUR_CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FzfiHbEAf5a"
   },
   "source": [
    "Problem 3-5. Implement *find_nonsingleton_words*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ZoFWTR5-AgKI"
   },
   "outputs": [],
   "source": [
    "def find_nonsingleton_words(text: str) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Split the string |text| by whitespace and return the set of words that\n",
    "    occur more than once.\n",
    "    You might find it useful to use collections.defaultdict(int).\n",
    "    \"\"\"\n",
    "    # BEGIN_YOUR_CODE (our solution is 4 lines of code, but don't worry if you deviate from this)\n",
    "    raise Exception(\"Not implemented yet\")\n",
    "    # END_YOUR_CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaiRADunaalj"
   },
   "source": [
    "Solution Evaluation Codes for Problem 3-1~3-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnMchwLX69qe"
   },
   "outputs": [],
   "source": [
    "# Problem 3-1\n",
    "result = get_first_alphabetical_word(\"apple banana orange\")\n",
    "print(result)  # Output will be \"apple\"\n",
    "\n",
    "# Problem 3-2\n",
    "# Define two locations as pairs of numbers\n",
    "loc1 = (3, 4)\n",
    "loc2 = (0, 0)\n",
    "\n",
    "# Call the function to calculate the Euclidean distance between loc1 and loc2\n",
    "distance = get_euclidean_dist(loc1, loc2)\n",
    "print(distance)  # Output will be approximately 5.0\n",
    "\n",
    "# Problem 3-3\n",
    "# Define two vectors\n",
    "vector1 = [1., 2., 3.]\n",
    "vector2 = [4., 5., 6.]\n",
    "\n",
    "# Call the function to calculate the cosine similarity between vector1 and vector2\n",
    "similarity = cosine_similarity(vector1, vector2)\n",
    "print(similarity)  # Output will be approximately 0.97463\n",
    "\n",
    "# Problem 3-4\n",
    "# Define two sparse vectors represented as collections.defaultdict(float)\n",
    "v1 = DefaultDict(float, {'a': 1.0, 'b': 2.0, 'c': 0.0})\n",
    "v2 = DefaultDict(float, {'a': 0.0, 'b': 3.0, 'c': 4.0})\n",
    "\n",
    "# Call the function to compute the dot product between v1 and v2\n",
    "dot_product = sparse_vector_dot_product(v1, v2)\n",
    "print(dot_product)  # Output will be 6.0\n",
    "\n",
    "# Problem 3-5\n",
    "# Defining the text\n",
    "text = \"apple banana orange apple banana\"\n",
    "\n",
    "# Calling the function to find nonsingleton words\n",
    "result = find_nonsingleton_words(text)\n",
    "print(result)  # Output will be {'apple', 'banana'}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
