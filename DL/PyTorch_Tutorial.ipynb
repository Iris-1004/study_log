{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HI43aS5mRO1s"
   },
   "source": [
    "# PyTorch Introduction\n",
    "Welcome to the PyTorch tutorial for deep learning! If you haven't already, enable a GPU for this colab instance by doing \"Edit\" -> \"Notebook settings\" -> \"Hardware accelerator\" drop-down -> \"GPU\" -> \"Save\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7cLA7izR_zl"
   },
   "source": [
    "Let's make sure we're using the right Python and PyTorch versions, and that we have a GPU at our disposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I12wdApTZC_H",
    "outputId": "bd8fcdbc-fee6-4174-db06-d693be5fa9f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version info: 2.3.1\n",
      "PyTorch detects a GPU: False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "#print(f'Python version info: {sys.version}')\n",
    "print(f'PyTorch version info: {torch.__version__}')\n",
    "print(f'PyTorch detects a GPU: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptKO3cRFTjWo"
   },
   "source": [
    "# Overview\n",
    "We'll begin by doing some MNIST classification, starting from low-level operations and gradually replacing chunks using `torch` abstractions such as `torch.nn.Module`, `torch.optim.SGD`, and `torch.utils.data.DataLoader`. (Much of this content is adapted from [this tutorial](https://pytorch.org/tutorials/beginner/nn_tutorial.html) by Jeremy Howard.) We'll then proceed to a whirlwind tour over PyTorch features that we suspect will be relevant for your homeworks for this course. Finally, we'll see some tips and tricks for debugging and getting help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8t8qKU2yVE5Q"
   },
   "source": [
    "# PyTorch Basics via MNIST\n",
    "### MNIST\n",
    "Download MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-wYk1d8CiBXy"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/main/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7K4tLsIVURi"
   },
   "source": [
    "Load MNIST into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EzxqdhhKVTMA"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_val, y_val), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouKpbI6DWYWx"
   },
   "source": [
    "The data currently exists as NumPy arrays. Let's take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "EG9KpubhWbNZ",
    "outputId": "abfef340-2894-4b8a-bf2a-32df85c1d48f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training inputs: shape (50000, 784), dtype float32\n",
      "training outputs: shape (50000,), dtype int64\n",
      "input range: (0.0, 0.99609375)\n",
      "label range: (0, 9)\n",
      "label of training example 12: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(f'training inputs: shape {x_train.shape}, dtype {x_train.dtype}')\n",
    "print(f'training outputs: shape {y_train.shape}, dtype {y_train.dtype}')\n",
    "print(f'input range: {x_train.min(), x_train.max()}')\n",
    "print(f'label range: {y_train.min(), y_train.max()}')\n",
    "\n",
    "i_example = 12\n",
    "x_train_example = x_train[i_example].reshape((28, 28))\n",
    "y_train_example = y_train[i_example]\n",
    "plt.imshow(x_train_example, cmap='gray')\n",
    "print(f'label of training example {i_example}: {y_train_example}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COOGtiMZXqYq"
   },
   "source": [
    "We need to convert the data into PyTorch tensors. For ease of use, tensors have some familiar attributes and methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VEk34MTIVfh2",
    "outputId": "3ac64859-9c71-451a-ca4a-60c3c8a18438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training inputs: shape torch.Size([50000, 784]), dtype torch.float32\n",
      "training outputs: shape torch.Size([50000]), dtype torch.int64\n",
      "input range: (tensor(0.), tensor(0.9961))\n",
      "label range: (tensor(0), tensor(9))\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_val, y_val = map(torch.tensor, (x_train, y_train, x_val, y_val))\n",
    "print(f'training inputs: shape {x_train.shape}, dtype {x_train.dtype}')\n",
    "print(f'training outputs: shape {y_train.shape}, dtype {y_train.dtype}')\n",
    "\n",
    "print(f'input range: {x_train.min(), x_train.max()}')\n",
    "print(f'label range: {y_train.min(), y_train.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuLs5f2bcwXU"
   },
   "source": [
    "### Bare Metal MNIST\n",
    "We will first train a model for classifying MNIST digits with nothing but tensor and gradient operations. We'll later substitute out chunks of this code with the appropriate PyTorch abstractions.\n",
    "\n",
    "To keep things simple, for this we'll use a linear model. For a single example, the model is\n",
    "$$ z = W^\\top x + b $$\n",
    "where $W \\in \\mathbb{R}^{784 \\times 10}$ and $b \\in \\mathbb{R}^{10}$ are the parameters to be learned, $x \\in [0, 1]^{784}$ is the MNIST image, and $z \\in \\mathbb{R}^{10}$ are the logits of the categorical distribution for the label of $x$.\n",
    "\n",
    "To obtain categorical parameters from the logits, we do\n",
    "$$ p = \\text{softmax}(z) = \\frac{1}{\\sum_j \\exp(z_j)} \\exp(z).$$\n",
    "\n",
    "The label $y \\in \\{0, \\dots, 9\\}$ implicitly defines a one-hot categorical parameter vector $y' \\in \\{0, 1\\}^{10}$, where $y$ corresponds to the index of $y'$ that is 1. The negative log-likelihood is then\n",
    "$$ \\text{nll}(p, y) = - \\sum_{i=0}^{9} y'_i \\log(p_i) = -\\log(p_y)$$\n",
    "\n",
    "Note that our implementation will assume batched inputs with a batch size of $B$. That is,\n",
    "$$x_b = \\begin{bmatrix} x_1^\\top \\\\ \\vdots \\\\ x_B^\\top \\end{bmatrix} \\in [0, 1]^{B \\times 784}.$$ We can vectorize the above operations to process all $B$ inputs at once (naively using `for` loops is much, much slower). For example, to compute the logits, we have\n",
    "$$z_b = x_b W + \\begin{bmatrix} b^\\top \\\\ \\vdots \\\\ b^\\top \\end{bmatrix} \\in \\mathbb{R}^{B \\times 10}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dZEHIaizc3CU"
   },
   "outputs": [],
   "source": [
    "W = torch.randn(784, 10, requires_grad=True)\n",
    "b = torch.randn(10, requires_grad=True)\n",
    "\n",
    "def logits(x_b, W, b):\n",
    "    return x_b @ W + b    # @ matrix multiplication, addition is broadcasted\n",
    "\n",
    "def log_softmax(z_b):\n",
    "    return z_b - torch.logsumexp(z_b, dim=1, keepdim=True)  # combining log and softmax is more numerically stable\n",
    "\n",
    "def negative_log_likelihood(logp_b, y_b):\n",
    "    return -torch.mean(logp_b[range(y_b.shape[0]), y_b])   # indexing trick\n",
    "\n",
    "def accuracy(logit_b, y_b):\n",
    "    return (logit_b.argmax(dim=1) == y_b).float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQYMuIF7i87C"
   },
   "source": [
    "Note that the `requires_grad` keyword argument/attribute determines whether a tensor is a constant or a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0vC_MuGOjDTn",
    "outputId": "e012ae48-96fc-43e1-8f54-e29b835a0986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(b.requires_grad)\n",
    "print(y_train.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrS8cR3OiARG"
   },
   "source": [
    "### Computation Graph\n",
    "Now we have the opportunity to look at some of PyTorch's core mechanics: reverse-mode automatic differentiation (a.k.a. backpropagation) on a dynamic computation graph. Let's take a batch of training data and compute the average loss over the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LGQELJgRg_TY"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "x_b, y_b = x_train[:batch_size], y_train[:batch_size]\n",
    "\n",
    "def loss_fn(W, b, x_b, y_b):\n",
    "    logit_b = logits(x_b, W, b)\n",
    "    logp_b = log_softmax(logit_b)\n",
    "    loss = negative_log_likelihood(logp_b, y_b)\n",
    "    return loss\n",
    "\n",
    "loss = loss_fn(W, b, x_b, y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YpM1c2sj-GN"
   },
   "source": [
    "Computations like the above are automagically recorded on a computation graph. Let's take a peek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iab2ejfRlpLv",
    "outputId": "0e250a34-de17-4afb-b7c9-71bc3aa5ee0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchviz\n",
      "  Downloading torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\envs\\ju_env\\lib\\site-packages (from torchviz) (2.3.1)\n",
      "Collecting graphviz (from torchviz)\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\ju_env\\lib\\site-packages (from torch->torchviz) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\anaconda3\\envs\\ju_env\\lib\\site-packages (from torch->torchviz) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3\\envs\\ju_env\\lib\\site-packages (from torch->torchviz) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\envs\\ju_env\\lib\\site-packages (from torch->torchviz) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\envs\\ju_env\\lib\\site-packages (from torch->torchviz) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\envs\\ju_env\\lib\\site-packages (from torch->torchviz) (2024.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\envs\\ju_env\\lib\\site-packages (from jinja2->torch->torchviz) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\envs\\ju_env\\lib\\site-packages (from sympy->torch->torchviz) (1.3.0)\n",
      "Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: graphviz, torchviz\n",
      "Successfully installed graphviz-0.20.3 torchviz-0.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 764
    },
    "id": "5zVVH_dkkaeq",
    "outputId": "241fbd09-d40f-4a89-9e32-8bde1f54b859"
   },
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\ju_env\\lib\\site-packages\\graphviz\\backend\\execute.py:76\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPIPE\n\u001b[1;32m---> 76\u001b[0m     proc \u001b[38;5;241m=\u001b[39m \u001b[43m_run_input_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ju_env\\lib\\site-packages\\graphviz\\backend\\execute.py:96\u001b[0m, in \u001b[0;36m_run_input_lines\u001b[1;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_input_lines\u001b[39m(cmd, input_lines, \u001b[38;5;241m*\u001b[39m, kwargs):\n\u001b[1;32m---> 96\u001b[0m     popen \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(cmd, stdin\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     98\u001b[0m     stdin_write \u001b[38;5;241m=\u001b[39m popen\u001b[38;5;241m.\u001b[39mstdin\u001b[38;5;241m.\u001b[39mwrite\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ju_env\\lib\\subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    948\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    949\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ju_env\\lib\\subprocess.py:1436\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1435\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1436\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1438\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1440\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1442\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1444\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1449\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1450\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 지정된 파일을 찾을 수 없습니다",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\ju_env\\lib\\site-packages\\IPython\\core\\formatters.py:974\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    971\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 974\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ju_env\\lib\\site-packages\\graphviz\\jupyter_integration.py:98\u001b[0m, in \u001b[0;36mJupyterIntegration._repr_mimebundle_\u001b[1;34m(self, include, exclude, **_)\u001b[0m\n\u001b[0;32m     96\u001b[0m include \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(include) \u001b[38;5;28;01mif\u001b[39;00m include \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jupyter_mimetype}\n\u001b[0;32m     97\u001b[0m include \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(exclude \u001b[38;5;129;01mor\u001b[39;00m [])\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {mimetype: \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method_name)()\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m mimetype, method_name \u001b[38;5;129;01min\u001b[39;00m MIME_TYPES\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mimetype \u001b[38;5;129;01min\u001b[39;00m include}\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ju_env\\lib\\site-packages\\graphviz\\jupyter_integration.py:98\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     96\u001b[0m include \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(include) \u001b[38;5;28;01mif\u001b[39;00m include \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jupyter_mimetype}\n\u001b[0;32m     97\u001b[0m include \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(exclude \u001b[38;5;129;01mor\u001b[39;00m [])\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {mimetype: \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m mimetype, method_name \u001b[38;5;129;01min\u001b[39;00m MIME_TYPES\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mimetype \u001b[38;5;129;01min\u001b[39;00m include}\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ju_env\\lib\\site-packages\\graphviz\\jupyter_integration.py:112\u001b[0m, in \u001b[0;36mJupyterIntegration._repr_image_svg_xml\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr_image_svg_xml\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msvg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSVG_ENCODING\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ju_env\\lib\\site-packages\\graphviz\\piping.py:104\u001b[0m, in \u001b[0;36mPipe.pipe\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpipe\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     56\u001b[0m          \u001b[38;5;28mformat\u001b[39m: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     57\u001b[0m          renderer: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m          engine: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     62\u001b[0m          encoding: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mUnion[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the source piped through the Graphviz layout command.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m        '<?xml version='\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipe_legacy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneato_no_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ju_env\\lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ju_env\\lib\\site-packages\\graphviz\\piping.py:121\u001b[0m, in \u001b[0;36mPipe._pipe_legacy\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@_tools\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecate_positional_args(supported_number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe_legacy\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    114\u001b[0m                  \u001b[38;5;28mformat\u001b[39m: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    119\u001b[0m                  engine: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    120\u001b[0m                  encoding: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mUnion[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipe_future\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneato_no_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ju_env\\lib\\site-packages\\graphviz\\piping.py:149\u001b[0m, in \u001b[0;36mPipe._pipe_future\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mlookup(encoding) \u001b[38;5;129;01mis\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding):\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;66;03m# common case: both stdin and stdout need the same encoding\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipe_lines_string(\u001b[38;5;241m*\u001b[39margs, encoding\u001b[38;5;241m=\u001b[39mencoding, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m         raw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipe_lines(\u001b[38;5;241m*\u001b[39margs, input_encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ju_env\\lib\\site-packages\\graphviz\\backend\\piping.py:212\u001b[0m, in \u001b[0;36mpipe_lines_string\u001b[1;34m(engine, format, input_lines, encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[0;32m    206\u001b[0m cmd \u001b[38;5;241m=\u001b[39m dot_command\u001b[38;5;241m.\u001b[39mcommand(engine, \u001b[38;5;28mformat\u001b[39m,\n\u001b[0;32m    207\u001b[0m                           renderer\u001b[38;5;241m=\u001b[39mrenderer,\n\u001b[0;32m    208\u001b[0m                           formatter\u001b[38;5;241m=\u001b[39mformatter,\n\u001b[0;32m    209\u001b[0m                           neato_no_op\u001b[38;5;241m=\u001b[39mneato_no_op)\n\u001b[0;32m    210\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_lines\u001b[39m\u001b[38;5;124m'\u001b[39m: input_lines, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m: encoding}\n\u001b[1;32m--> 212\u001b[0m proc \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mrun_check(cmd, capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, quiet\u001b[38;5;241m=\u001b[39mquiet, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ju_env\\lib\\site-packages\\graphviz\\backend\\execute.py:81\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n\u001b[1;32m---> 81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x23794b67f10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchviz\n",
    "torchviz.make_dot(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwJ-5hG7mTOL"
   },
   "source": [
    "We can actually inspect tensors to see that each non-leaf variable tensor records its gradient function based on how it was obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gbRLFWkWmUY8",
    "outputId": "2834601f-910c-4eae-f260-48700b146d8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<NegBackward0 object at 0x7eee043e6860>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(b.grad_fn)    # leaf variable\n",
    "print(loss.grad_fn)\n",
    "print(x_b.grad_fn)  # not a variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0u88oEuRSZAG"
   },
   "source": [
    "### Using `autograd.grad` to Compute Gradients\n",
    "We can now use reverse-mode automatic differentiation to compute the gradient of the loss with respect to our parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4IuGz-vNru5",
    "outputId": "d461ff7b-b3ef-447b-88c2-47692d81e35e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0825,  0.0999, -0.0625,  0.0776, -0.1103,  0.1203, -0.0714,  0.0043,\n",
      "         0.1651, -0.1404])\n"
     ]
    }
   ],
   "source": [
    "from torch import autograd\n",
    "loss = loss_fn(W, b, x_b, y_b)\n",
    "W_grad, b_grad = autograd.grad(loss, inputs=(W, b))\n",
    "print(b_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1U8J8ujfoSp"
   },
   "source": [
    "We're now ready to optimize our linear MNIST model. Each iteration consists of the following steps:\n",
    "* Sample a batch of training data.\n",
    "* Compute the logits from the inputs using the model parameters.\n",
    "* Compute a scalar loss from the logits and labels.\n",
    "* Compute the gradient of the loss with respect to the parameters.\n",
    "* Update the model parameters using the gradient.\n",
    "\n",
    "Note that the last step is done in a context manager that disables the construction of the computation graph.\n",
    "\n",
    "To check whether our optimization was successful, we'll look at the accuracy on the training data before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iABo_4DPoInh",
    "outputId": "4af6d3c3-d9c4-4e95-97e2-64fd1e30cbb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before: 0.09449999779462814\n",
      "accuracy after: 0.8813999891281128\n"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "num_epochs = 2\n",
    "\n",
    "def train(W, b):\n",
    "    print(f'accuracy before: {accuracy(logits(x_train, W, b), y_train)}')\n",
    "\n",
    "    for i_epoch in range(num_epochs):\n",
    "        i_batch_start = 0\n",
    "        while i_batch_start + batch_size < x_train.shape[0]:\n",
    "            x_b = x_train[i_batch_start:i_batch_start + batch_size]\n",
    "            y_b = y_train[i_batch_start:i_batch_start + batch_size]\n",
    "            i_batch_start += batch_size\n",
    "\n",
    "            logit_b = logits(x_b, W, b)\n",
    "            logp_b = log_softmax(logit_b)\n",
    "            loss = negative_log_likelihood(logp_b, y_b)\n",
    "            W_grad, b_grad = autograd.grad(loss, inputs=(W, b))\n",
    "\n",
    "            with torch.no_grad():   # we don't need gradients for this\n",
    "                W -= lr * W_grad\n",
    "                b -= lr * b_grad\n",
    "\n",
    "    print(f'accuracy after: {accuracy(logits(x_train, W, b), y_train)}')\n",
    "\n",
    "W = torch.randn(784, 10, requires_grad=True)\n",
    "b = torch.randn(10, requires_grad=True)\n",
    "train(W, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYArnyJ_nDCt"
   },
   "source": [
    "### Using `backward` to Compute Gradients\n",
    "An alternative to using `autograd.grad` is to call `backward()` on the loss tensor. This _accumulates_ gradients of leaf tensors into their `grad` attribute. (Note that with this we don't need to specify the variables we're taking the gradient with respect to, nor do we obtain the gradients as output from the function call.)\n",
    "\n",
    "When we're done using a gradient in a `grad` attribute, we should reset it to 0, else repeated accumulations may occur. We can do this with the `Tensor` method `zero_()`. (Note that the `_` signifies that the operation modifies the tensor in-place.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ta5qt6V1kPAE",
    "outputId": "fc850905-28b5-4207-a71e-019df0815384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before computing gradients\n",
      "None\n",
      "after forward pass and calling backward()\n",
      "tensor([ 0.0006,  0.0056, -0.0161,  0.0261, -0.0080,  0.0063, -0.0055,  0.0243,\n",
      "        -0.0118, -0.0216])\n",
      "after another forward pass and calling backward() again\n",
      "tensor([ 0.0012,  0.0113, -0.0321,  0.0523, -0.0160,  0.0126, -0.0109,  0.0486,\n",
      "        -0.0236, -0.0433])\n",
      "after calling zero_()\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print('before computing gradients')\n",
    "print(b.grad)\n",
    "\n",
    "loss = loss_fn(W, b, x_b, y_b)\n",
    "loss.backward()\n",
    "print('after forward pass and calling backward()')\n",
    "print(b.grad)\n",
    "\n",
    "loss = loss_fn(W, b, x_b, y_b)\n",
    "loss.backward()\n",
    "print('after another forward pass and calling backward() again')\n",
    "print(b.grad)\n",
    "\n",
    "b.grad.zero_()\n",
    "print('after calling zero_()')\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9gxa-qsSc0i"
   },
   "source": [
    "When should you use `autograd.grad` vs. `backward`? In general, `backward` is more convenient, but there are times when you need more fine-grained control over gradient computation. Let's see what the training code looks like when we use `backward`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYhQfdJDLJyj",
    "outputId": "c3018ad7-67e7-4347-b3c4-ba317e572e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before: 0.12430000305175781\n",
      "accuracy after: 0.8812599778175354\n"
     ]
    }
   ],
   "source": [
    "def train(W, b):\n",
    "    print(f'accuracy before: {accuracy(logits(x_train, W, b), y_train)}')\n",
    "\n",
    "    for i_epoch in range(num_epochs):\n",
    "        i_batch_start = 0\n",
    "        while i_batch_start + batch_size < x_train.shape[0]:\n",
    "            x_b = x_train[i_batch_start:i_batch_start + batch_size]\n",
    "            y_b = y_train[i_batch_start:i_batch_start + batch_size]\n",
    "            i_batch_start += batch_size\n",
    "\n",
    "            logit_b = logits(x_b, W, b)\n",
    "            logp_b = log_softmax(logit_b)\n",
    "            loss = negative_log_likelihood(logp_b, y_b)\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                W -= lr * W.grad\n",
    "                b -= lr * b.grad\n",
    "                W.grad.zero_()\n",
    "                b.grad.zero_()\n",
    "\n",
    "    print(f'accuracy after: {accuracy(logits(x_train, W, b), y_train)}')\n",
    "\n",
    "W = torch.randn(784, 10, requires_grad=True)\n",
    "b = torch.randn(10, requires_grad=True)\n",
    "train(W, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1MUJ0cfxD58"
   },
   "source": [
    "### `nn.functional`\n",
    "Now, let's refactor and extend our training code by allowing ourselves to use other `torch` modules. We'll first look at `torch.nn`.\n",
    "\n",
    "`nn.functional` (commonly abbreviated as just `F`) includes many useful functions, e.g. loss functions and activation functions. In particular, `F.cross_entropy` combines the `log_softmax` and `negative_log_likelihood` functions into one.\n",
    "\n",
    "If you're used to using TensorFlow's [CategoricalCrossentropy loss](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy), note that `F.cross_entropy` takes integer labels, not one-hot labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5A2M3dY4xpfs",
    "outputId": "6eca3e4c-9895-43dc-f382-5e1fa29a758c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3632)\n",
      "tensor(0.3632)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "with torch.no_grad():\n",
    "    logit_b = logits(x_b, W, b)\n",
    "    print(negative_log_likelihood(log_softmax(logit_b), y_b))\n",
    "    print(F.cross_entropy(logit_b, y_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I91UsJOmyv1b"
   },
   "source": [
    "### `nn.Module`\n",
    "`nn.Module` is a useful class that corresponds loosely to an intuitive notion of a parameterized model. It\n",
    "* registers `nn.Parameter`s, which are essentially variable tensors, as attributes\n",
    "* holds as the `forward` method the model's forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MIN1V4b7yvGF"
   },
   "outputs": [],
   "source": [
    "class MNISTLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.randn(784, 10))\n",
    "        self.b = nn.Parameter(torch.randn(10))\n",
    "\n",
    "    def forward(self, x_b):\n",
    "        return x_b @ self.W + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mpd724uU3Vkg"
   },
   "source": [
    "Using the `nn.Module` can be very convenient. For example, previously we had to manually zero the `grad` attribute of `W` and `b`. We can now use the `parameters` method, which returns an iterator over module parameters, and the `zero_grad` method, which zeros the `grad` attribute of every module parameter.\n",
    "\n",
    "After substituting code for the model forward pass, the loss computation, the optimization step, and the gradient zeroing, the training code now looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5SJlK8y24BHn",
    "outputId": "77aa8b94-b076-4ab9-a737-e3c100f16580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before: 0.10136000066995621\n",
      "accuracy after: 0.8794199824333191\n"
     ]
    }
   ],
   "source": [
    "def train(model):\n",
    "    print(f'accuracy before: {accuracy(model(x_train), y_train)}')\n",
    "\n",
    "    for i_epoch in range(num_epochs):\n",
    "        i_batch_start = 0\n",
    "        while i_batch_start + batch_size < x_train.shape[0]:\n",
    "            x_b = x_train[i_batch_start:i_batch_start + batch_size]\n",
    "            y_b = y_train[i_batch_start:i_batch_start + batch_size]\n",
    "            i_batch_start += batch_size\n",
    "\n",
    "            logit_b = model(x_b)    # an nn.Module is callable\n",
    "            loss = F.cross_entropy(logit_b, y_b)\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= lr * p.grad\n",
    "                model.zero_grad()\n",
    "\n",
    "    print(f'accuracy after: {accuracy(model(x_train), y_train)}')\n",
    "\n",
    "train(MNISTLinear())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czAS_2oo4qrP"
   },
   "source": [
    "`nn` contains many `nn.Module` subclasses that correspond to commonly used chunks of computation. One such \"layer\" is the linear model we've been using! We can replace our `MNISTLinear` class with an `nn.Linear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ed2QkQ768CLI",
    "outputId": "1d6a9a6c-6888-49bc-96c6-1f5ccd32c7d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before: 0.07503999769687653\n",
      "accuracy after: 0.9118599891662598\n"
     ]
    }
   ],
   "source": [
    "train(nn.Linear(784, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2qhStDy8lrP"
   },
   "source": [
    "Our optimization went differently in 2 epochs this time around. This is probably because the parameters in `nn.Linear` are [initialized slightly differently](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html). It's always important to read documentation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkOLJWAH8zYD"
   },
   "source": [
    "### MNIST MLP\n",
    "What if we want to use a two-layer fully-connected network? `nn.Module`s can register `nn.Module` attributes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60V-yAKM5m00",
    "outputId": "9e3bd479-1272-4583-a78c-e71f97eb72e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before: 0.12963999807834625\n",
      "accuracy after: 0.9632800221443176\n"
     ]
    }
   ],
   "source": [
    "class MNISTMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(784, 64)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x_b):\n",
    "        return self.linear2(self.activation(self.linear1(x_b)))\n",
    "        # return self.linear2(F.relu(self.linear1(x_b)))\n",
    "\n",
    "train(MNISTMLP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "oo28kG2KABLp"
   },
   "outputs": [],
   "source": [
    "new_model = nn.Sequential(\n",
    "    nn.Linear(784, 64),\n",
    "    nn.ReLU(),    ## (c.f., F.relu) nn.ReLU() is more commonly used when defining layers in a sequential model or when you want to include non-linearities as explicit layers.\n",
    "    nn.Linear(64, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eG2yPUjhYzzx"
   },
   "source": [
    "##Saving/Loading pre-trained weights\n",
    "Sometimes multiple people may have to use the same network. It can take a lot of time for everyone to train their network from scratch. It is environmentally also disastrous as the carbon footprint of training large networks is very huge.\n",
    "\n",
    "It would be better if we could train and save weights for our network, and reuse them later if we need to. PyTorch gives us ways to do this easily!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BjZ2iBpbbPDS",
    "outputId": "55a8a615-78f0-4c2c-d27c-64e618ee5a52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before: 0.14815999567508698\n",
      "accuracy after: 0.9593799710273743\n"
     ]
    }
   ],
   "source": [
    "network = MNISTMLP()\n",
    "train(network)\n",
    "\n",
    "torch.save(network.state_dict(), \"network.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ew8Ken2b4He"
   },
   "source": [
    "The above code saves the network's weights to the given path, in this case \"network.pt\". Now we will show that loading the model's weight without retraining it from scratch retrieves prior performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4doKE58-cJV3",
    "outputId": "bd670223-f204-4386-da7d-483aa7903ec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of initialized network: 0.11466000229120255\n",
      "accuracy after loading weights: 0.9593799710273743\n"
     ]
    }
   ],
   "source": [
    "network = MNISTMLP()\n",
    "print(f'accuracy of initialized network: {accuracy(network(x_train), y_train)}')\n",
    "\n",
    "network.load_state_dict(torch.load(\"network.pt\"))\n",
    "print(f'accuracy after loading weights: {accuracy(network(x_train), y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYXTLH477ooG"
   },
   "source": [
    "### Are You Registered?\n",
    "`nn.Module`s [have some specific rules](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) regarding what attributes are properly registered (i.e. identified as part of the model). We've seen that `nn.Parameter`s and `nn.Module`s are, but most Python objects are not. For example, you might consider it cleaner to implement the `MNISTMLP` this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8sIQ_XOf-NM1",
    "outputId": "f8e36e07-d016-4093-f529-2d0cbd6f778d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before: 0.07394000142812729\n",
      "accuracy after: 0.07394000142812729\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "class MNISTMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = [\n",
    "            nn.Linear(784, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        ]\n",
    "\n",
    "    def forward(self, x_b):\n",
    "        for layer in self.layers:\n",
    "            x_b = layer(x_b)\n",
    "        return x_b\n",
    "\n",
    "train(MNISTMLP())\n",
    "print(list(MNISTMLP().parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mn3Ogmn4-umv"
   },
   "source": [
    "Uh oh! Even though the `layers` list has `nn.Module`s, it itself wasn't recognized as a registerable attribute. To get around this, we have the `nn.ModuleList`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IA21B41t-7fL",
    "outputId": "58131a23-75d9-4206-b01d-6a72c1f7fa1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before: 0.07378000020980835\n",
      "accuracy after: 0.9567000269889832\n"
     ]
    }
   ],
   "source": [
    "class MNISTMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Linear(784, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x_b):\n",
    "        for layer in self.layers:\n",
    "            x_b = layer(x_b)\n",
    "        return x_b\n",
    "\n",
    "train(MNISTMLP())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sN4KUQfu_QW7"
   },
   "source": [
    "### `nn.Sequential`\n",
    "It's pretty common to have a sequence of layers we want to iteratively apply onto an input. We can replace the `for` loop business in the forward pass by using an `nn.Sequential` container, a very commonly used abstraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rooDuNM2_C4S",
    "outputId": "68ba0d7a-fa19-4bf2-e7cb-2f0348b8a387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before: 0.11187999695539474\n",
      "accuracy after: 0.9663400053977966\n"
     ]
    }
   ],
   "source": [
    "train(nn.Sequential(\n",
    "    nn.Linear(784, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zx745oji_vrm"
   },
   "source": [
    "### `torch.optim`\n",
    "`torch.optim` contains implementations of many common optimization algorithms. When initializing an optimizer instance, we need to pass in the model parameters. Now, instead of manually coding the update rule, we call the optimizer's `step` method. The optimizer can also handle resetting parameter gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tupyWULJ7ZpU",
    "outputId": "e99e9c33-1de6-4d24-b84d-39e428734556"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before: 0.1292800009250641\n",
      "accuracy after: 0.9643200039863586\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "def train(model):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    print(f'accuracy before: {accuracy(model(x_train), y_train)}')\n",
    "\n",
    "    for i_epoch in range(num_epochs):\n",
    "        i_batch_start = 0\n",
    "        while i_batch_start + batch_size < x_train.shape[0]:\n",
    "            x_b = x_train[i_batch_start:i_batch_start + batch_size]\n",
    "            y_b = y_train[i_batch_start:i_batch_start + batch_size]\n",
    "            i_batch_start += batch_size\n",
    "\n",
    "            logit_b = model(x_b)\n",
    "            loss = F.cross_entropy(logit_b, y_b)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad() #\n",
    "\n",
    "    print(f'accuracy after: {accuracy(model(x_train), y_train)}')\n",
    "\n",
    "train(MNISTMLP())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7SRGPQQ-VSB"
   },
   "source": [
    "### `torch.utils.data`\n",
    "Notice how we are manually slicing the `x_train` and `y_train` tensors to get batches. There's a more convenient way to do this:\n",
    "`torch.utils.data` features the `Dataset`, `Sampler`, and `DataLoader` abstractions, which are useful for transforming, sampling, and iterating over data. Let's implement a custom `Dataset` subclass for MNIST which we can then use to instantiate a `DataLoader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wL0iPSSRKpER",
    "outputId": "e5f79553-a7c5-4c62-9283-1e5df481dac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before: 0.09709999710321426\n",
      "accuracy after: 0.9580199718475342\n"
     ]
    }
   ],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class MNISTDataset(data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "dataset_train = MNISTDataset(x_train, y_train)\n",
    "dataloader_train = data.DataLoader(dataset_train, batch_size=batch_size)\n",
    "\n",
    "def train(model):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    print(f'accuracy before: {accuracy(model(x_train), y_train)}')\n",
    "\n",
    "    for i_epoch in range(num_epochs):\n",
    "        for x_b, y_b in dataloader_train:   # dataloaders are iterators\n",
    "            logit_b = model(x_b)\n",
    "            loss = F.cross_entropy(logit_b, y_b)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    print(f'accuracy after: {accuracy(model(x_train), y_train)}')\n",
    "\n",
    "train(MNISTMLP())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3flJEs4LKZK"
   },
   "source": [
    "### Using a GPU\n",
    "Now, let's see how to use a GPU in PyTorch. Every tensor has a `device` attribute (default: `'cpu'`). GPU-accelerated computation requires the involved tensors to all be on device `'cuda'`. The `to` method is a handy way to move tensors around.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWosupXrT_IV",
    "outputId": "212842ae-8e85-4f23-887c-b1a8df421a0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.)\n",
    "print(x.device)\n",
    "x = x.to('cuda')\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6ms19-qYfHB"
   },
   "source": [
    "The `nn.Module` also has a `to` method that transfers all parameters (and buffer items) to a specified device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EeokNbD3YDXr",
    "outputId": "69fb71d3-0bf6-497f-f91a-1fabac2b109c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before: 0.12241999804973602\n",
      "accuracy after: 0.9627400040626526\n"
     ]
    }
   ],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "dataset_train = data.TensorDataset(x_train, y_train)\n",
    "dataloader_train = data.DataLoader(dataset_train, batch_size=batch_size)\n",
    "\n",
    "def train(model):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    print(f'accuracy before: {accuracy(model(x_train.to(\"cuda\")), y_train.to(\"cuda\"))}')\n",
    "\n",
    "    for i_epoch in range(num_epochs):\n",
    "        # model.linear1.parameters.requires_grad = False\n",
    "        for x_b, y_b in dataloader_train:\n",
    "            x_b, y_b = x_b.to('cuda'), y_b.to('cuda')\n",
    "            logit_b = model(x_b)\n",
    "            loss = F.cross_entropy(logit_b, y_b)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    print(f'accuracy after: {accuracy(model(x_train.to(\"cuda\")), y_train.to(\"cuda\"))}')\n",
    "\n",
    "train(MNISTMLP().to('cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eIKUTPPTVT2e"
   },
   "source": [
    "### Clean-up\n",
    "To wrap this section up, we'll refactor our code to facilitate assessing on both train and val data with data-loading, and using the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCtv2mcTAWSF",
    "outputId": "08aff5ef-e2cd-4301-f375-147a145748d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "train loss and acc: (2.304156875, 0.1068)\n",
      "val loss and acc: (2.3054654296875, 0.1086)\n",
      "after\n",
      "train loss and acc: (0.125459921875, 0.96072)\n",
      "val loss and acc: (0.13819859619140626, 0.9604)\n"
     ]
    }
   ],
   "source": [
    "dataset_val = data.TensorDataset(x_val, y_val)\n",
    "dataloader_val = data.DataLoader(dataset_val, batch_size=batch_size)\n",
    "\n",
    "def loss_fn(model, x_b, y_b):\n",
    "    logit_b = model(x_b)\n",
    "    loss = F.cross_entropy(logit_b, y_b)\n",
    "    return loss, y_b.shape[0]\n",
    "\n",
    "def accuracy(model, x_b, y_b):\n",
    "    logit_b = model(x_b)\n",
    "    accuracy = (logit_b.argmax(dim=1) == y_b).float().mean()\n",
    "    return accuracy, y_b.shape[0]\n",
    "\n",
    "def assess(model, dataloader):\n",
    "    loss_total_r, correct_r, n_r = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x_b, y_b in dataloader:\n",
    "            x_b, y_b = x_b.to('cuda'), y_b.to('cuda')\n",
    "            loss, n = loss_fn(model, x_b, y_b)\n",
    "            acc, n = accuracy(model, x_b, y_b)\n",
    "            loss_total_r += loss * n\n",
    "            correct_r += acc * n\n",
    "            n_r += n\n",
    "    loss_total_r, correct_r = loss_total_r.item(), correct_r.item()\n",
    "    return loss_total_r / n_r, correct_r / n_r\n",
    "\n",
    "def train(model, optimizer):\n",
    "    print('before')\n",
    "    print(f'train loss and acc: {assess(model, dataloader_train)}')\n",
    "    print(f'val loss and acc: {assess(model, dataloader_val)}')\n",
    "\n",
    "    for i_epoch in range(num_epochs):\n",
    "        for x_b, y_b in dataloader_train:\n",
    "            x_b, y_b = x_b.to('cuda'), y_b.to('cuda')\n",
    "            loss, _ = loss_fn(model, x_b, y_b)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    print('after')\n",
    "    print(f'train loss and acc: {assess(model, dataloader_train)}')\n",
    "    print(f'val loss and acc: {assess(model, dataloader_val)}')\n",
    "\n",
    "model = MNISTMLP().to('cuda')\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "train(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwUn0NLuVjeY"
   },
   "source": [
    "# Exploring Additional Features of PyTorch: A Quick Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkZ98YSob72X"
   },
   "source": [
    "### MNIST CNN\n",
    "2D convolutional layers expect an input of shape $(B, C, H, W)$ or `(batch, channels, height, width)`. For a batch of MNIST images, this is $(B, 1, 28, 28)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tfXPPG3gb_cz",
    "outputId": "ea24c9a6-318a-4a52-e3a4-028a300c7fa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "train loss and acc: (2.30217484375, 0.1029)\n",
      "val loss and acc: (2.30240390625, 0.1031)\n",
      "after\n",
      "train loss and acc: (0.03593005126953125, 0.98856)\n",
      "val loss and acc: (0.0557791748046875, 0.9844)\n"
     ]
    }
   ],
   "source": [
    "class MNISTCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=20, kernel_size=(5, 5), stride=1, padding=0),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Conv2d(in_channels=20, out_channels=50, kernel_size=(5, 5), stride=1, padding=0),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(800, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_b):\n",
    "        return self.layers(x_b.view((-1, 1, 28, 28)))\n",
    "\n",
    "model = MNISTCNN().to('cuda')\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "train(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLV7dSnk_xC4"
   },
   "source": [
    "### MNIST LSTM\n",
    "When constructed using the `batch_first=True` argument, `nn.LSTM`s expect inputs of shape $(B, L, D)$ or `(batch, sequence length, element size)`. We'll interpret the rows of the MNIST image as sequence elements, and compute the logits from the last LSTM output (i.e. wait for the LSTM to see the entire image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CSA3chD5Aiu_",
    "outputId": "05bec445-9931-4695-92d7-cfaf796a7aa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "train loss and acc: (2.306199375, 0.10202)\n",
      "val loss and acc: (2.30559921875, 0.103)\n",
      "after\n",
      "train loss and acc: (0.1735815625, 0.95046)\n",
      "val loss and acc: (0.171746826171875, 0.9503)\n"
     ]
    }
   ],
   "source": [
    "class MNISTLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.LSTM = nn.LSTM(input_size=28, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x_b):\n",
    "        out, _ = self.LSTM(x_b.view((-1, 28, 28)))  # out contains outputs at each iteration over the sequence\n",
    "        return self.linear(out[:, -1, :])   # only the out at the last iteration has seen the entire image\n",
    "\n",
    "model = MNISTLSTM().to('cuda')\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "train(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7gNjS2HEeEo"
   },
   "source": [
    "### `nn.Embedding`\n",
    "Oftentimes we will have categorical data with too many categories to comfortably convert into one-hot encodings. Examples of this include tokens in NLP and $(x,y)$ positions on a grid. One common way to process this data is to use an `nn.Embedding`, or a table of dense vectors that can be indexed by the categorical data. The dense vectors can be optimized. `nn.Embedding` supports advanced indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_45NPu8MHZMu",
    "outputId": "3783fa89-037e-4f48-a7d7-e9281adf92ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "True\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 4, 64])\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(num_embeddings=1000, embedding_dim=64) # Creating an Embedding Layer\n",
    "print(embedding(torch.tensor(42)).shape)  # Accessing a Specific Embedding\n",
    "print(embedding(torch.tensor(42)).requires_grad)  # Gradient Requirement\n",
    "indices = torch.tensor([        # Batch of Indices: 2 samples and each sample contains 4 indices\n",
    "    [0, 1, 42, 999],\n",
    "    [1, 1, 2, 3]\n",
    "])\n",
    "print(indices.shape)\n",
    "print(embedding(indices).shape) # Batch Embedding Lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4hyCvaoIq-c"
   },
   "source": [
    "If you're interested in NLP, a nice use of `nn.Embedding` and recurrent layers (`nn.GRU`) for natural language translation can be found in [this tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pun7z9zGqbvH"
   },
   "source": [
    "### `torch.distributions`\n",
    "Aside from conveniently providing commonly used methods (e.g. density/mass evaluation), one of the main features of this module is the use of the reparameterization trick to facilitate backpropagation through random samples to the underlying distribution parameters (and beyond)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BHyPfnxdJvc4",
    "outputId": "f4e5366a-2a50-46d0-8171-fee7507c3389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8607,  1.3125,  0.4873, -0.4322, -1.5565], grad_fn=<AddBackward0>)\n",
      "tensor(-2.1242)\n"
     ]
    }
   ],
   "source": [
    "from torch import distributions\n",
    "loc = torch.tensor(0., requires_grad=True)\n",
    "scale = torch.tensor(1., requires_grad=True)\n",
    "p = distributions.Normal(loc, scale)\n",
    "x = p.rsample(torch.Size([5]))\n",
    "print(x)    # grad_fn comes from reparameterization trick\n",
    "y = -torch.mean(x**2)\n",
    "y.backward()\n",
    "print(scale.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRZRNM6MLZMU"
   },
   "source": [
    "If we don't use `rsample`, we can't take gradients through the sampling step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "sWDu3fi6LN0y",
    "outputId": "ae4c0ff4-7dca-4c62-f924-6544a27828bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5960,  0.4004, -0.1672, -0.2244,  0.2670])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-694ee59c3544>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "x = p.sample(torch.Size([5]))\n",
    "print(x)\n",
    "y = -torch.sum(x**2)\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrIbkiJhNyRF"
   },
   "source": [
    "# Debugging, Documentation, and Getting Help\n",
    "If you are not coding in Jupyter notebooks, but in Python scripts. This means you won't have the interactivity of cell-based execution, but to the rescue comes `pdb`, the Python Debugger. Use it to\n",
    "\n",
    "*   set breakpoints in the code to interactively inspect program elements: `import pdb; pdb.set_trace()`\n",
    "*   automatically start a debugging session when an exception is thrown: `python -m pdb -c continue main.py`\n",
    "\n",
    "Both will be super, super useful.\n",
    "\n",
    "When something about PyTorch is confusing you, the first place to look is the [PyTorch documentation](https://pytorch.org/docs/stable/index.html). (The author of this tutorial consulted the documentation no fewer than 20 times when making it.) This is often the last place you need to look, but sometimes the [PyTorch forums](https://discuss.pytorch.org/) can be helpful, too. (Use the search tool!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5FIR5icqCax"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "GrIbkiJhNyRF"
   ],
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
