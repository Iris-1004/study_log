{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 평가 (Evaluation)\n",
        "\n",
        "## 성능평가지표\n",
        "\n",
        "### 1. 정확도 (Accuracy)"
      ],
      "metadata": {
        "id": "tjGSi6eABgw9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKO__vVRBZm7",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# 정확도 : 실제 새로운 데이터에서 모델의 예측 데이터가 Label과 얼마나 같은지를 판단하는 지표\n",
        "                 예측 결과과 동일한 데이터 건수\n",
        "  정확도 =   -----------------------------------\n",
        "                전체 예측 데이터 건수\n",
        "\n",
        "         : 직관적으로 모델의 예측 성능을 나타내는 지표\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "Y1fWODzdBeNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 왜곡을 일으키는 분류기\n",
        "class MyDummyClassfier(BaseEstimator):\n",
        "  def fit(self, X, y=None):\n",
        "    pass\n",
        "\n",
        "  # titanic feature 중에서 Sex Feature가 1이면 0, 0이면 1로 예측하는 모델\n",
        "  def predict(self, X):\n",
        "    pred = np.zeros((X.shape[0], 1))\n",
        "    for i in range(X.shape[0]):\n",
        "      if X['Sex'].iloc[i] == 1 :\n",
        "        pred[i] = 0\n",
        "      else :\n",
        "        pred[i] = 1\n",
        "      return pred"
      ],
      "metadata": {
        "id": "LRAdVdlBBeLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 처리 함수\n",
        "def fillna_nan(df):\n",
        "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "  df['Cabin'].fillna('N', inplace=True)\n",
        "  df['Embarked'].fillna('N', inplace=True)\n",
        "  return df\n",
        "\n",
        "# 레이블 인코딩\n",
        "def label_encoding_features(df):\n",
        "  features = ['Sex', 'Embarked']\n",
        "  for feature in features :\n",
        "    encoder = LabelEncoder()\n",
        "    df[feature] = encoder.fit_transform(df[feature])\n",
        "  return df\n",
        "\n",
        "# 모델에게 불필요한 특성(feature) 제거\n",
        "def drop_feature(df):\n",
        "  df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
        "  return df\n",
        "\n",
        "# 최종적으로 전처리를 수행할 함수\n",
        "def transform_features(df):\n",
        "  df = fillna_nan(df)\n",
        "  df = drop_feature(df)\n",
        "  df = label_encoding_features(df)\n",
        "  return df"
      ],
      "metadata": {
        "id": "GsdzEmZXBeIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로딩\n",
        "titanic_df = pd.read_csv('./titanic_train.csv')\n",
        "\n",
        "# target (label) 데이터\n",
        "y_titanic = titanic_df['Survived']\n",
        "\n",
        "# feature 데이터\n",
        "X_titanic = titanic_df.drop('Survived', axis=1)\n",
        "\n",
        "# feature 전처리\n",
        "X_titanic_df = transform_features(X_titanic)\n",
        "\n",
        "X_titanic_df.head()"
      ],
      "metadata": {
        "id": "u8_6KQ7mBeGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_titanic_df.info()"
      ],
      "metadata": {
        "id": "2Bl2PtnPGgKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 세트, 테스트 세트 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic, test_size=0.2, random_state=11)"
      ],
      "metadata": {
        "id": "G4oxUKDOBeEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 왜곡이 생기도록 만든 분류기로 학습/예측/평가\n",
        "my_clf = MyDummyClassfier()\n",
        "\n",
        "my_clf.fit(X_train, y_train)\n",
        "\n",
        "pred = my_clf.predict(X_test)\n",
        "\n",
        "print(f'왜곡이 생긴 모델의 정확도 : {accuracy_score(y_test, pred)}')"
      ],
      "metadata": {
        "id": "xDqWtrxCBeBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Confusion Matrix(오차 행렬)"
      ],
      "metadata": {
        "id": "VmSKSxiHHO8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('./confusion_matrix.png')"
      ],
      "metadata": {
        "id": "sp0vPymXGXTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# 오차행렬 (혼동행렬)\n",
        " : 학습된 모델이 예측을 수행하면서 얼만큼 헷갈리고 (confusion) 있는지도 함께 보여주는 지표\n",
        " : 오류가 얼마인지와 더불어 어떤 유형의 예측 오류가 있는지도 함께 나타내는 지표\n",
        "\n",
        "                       (TN + TP)\n",
        " 정확도 = --------------------------------------------\n",
        "                   (TN + FP + FN + TP)\n",
        "\n",
        "        =  예측 결과와 실제값이 동일한 수 / 전체 데이터\n",
        "'''"
      ],
      "metadata": {
        "id": "qsYB_AnUGXRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_test, pred)"
      ],
      "metadata": {
        "id": "EineLD2gGXPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Precision(정밀도)와 Recall(재현율)\n",
        "\n",
        "* 불균형한 데이터세트에서 정확도 보다 더 선호되는 평가지표\n",
        "\n",
        "* Positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가지표"
      ],
      "metadata": {
        "id": "uDnuoaL6OACq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# 정밀도 = TP / (FP + TP)\n",
        " : 예측을 Positive 한 대상 중에서 예측과 실제값이 Positive로 일치하는 데이터 비율\n",
        " : Positive 예측 성능을 더욱 정밀하게 측정하기 위한 평가 지표 - 양성 예측도\n",
        "\n",
        "# 재현율 = TP / (FN + TP)\n",
        " : 실제값 양성 중 모델이 정확히 양성이라고 예측한 비율. 민감도(Sensitivity), TPR(True Positive Rate)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "S2NJiNTpGXM0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "print(f'정밀도 : {precision_score(y_test, pred)}')\n",
        "print(f'재현율 : {recall_score(y_test, pred)}')"
      ],
      "metadata": {
        "id": "C1vWAnaaHKcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 타이타닉 데이터 기반 생존 판단 모델을 이용한 평가 수행"
      ],
      "metadata": {
        "id": "KSehPvnwBLV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확도, 정밀도, 재현율, 오차행렬 등을 한꺼번에 구하는 함수\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
        "\n",
        "def get_clf_eval(y_test, pred):\n",
        "  confusion = confusion_matrix(y_test, pred)\n",
        "  accuracy = accuracy_score(y_test, pred)\n",
        "  precision = precision_score(y_test, pred)\n",
        "  recall = recall_score(y_test, pred)\n",
        "\n",
        "  print('--- 오차 행렬 -----')\n",
        "  print(confusion)\n",
        "  print('-'*40)\n",
        "  print(f'정확도 : {accuracy}, 정밀도 : {precision}, 재현율 : {recall}')"
      ],
      "metadata": {
        "id": "LooQRytXHKZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로딩\n",
        "titanic_df = pd.read_csv('./titanic_train.csv')\n",
        "\n",
        "# target (label) 데이터\n",
        "y_titanic = titanic_df['Survived']\n",
        "\n",
        "# feature 데이터\n",
        "X_titanic = titanic_df.drop('Survived', axis=1)\n",
        "\n",
        "# feature 전처리\n",
        "X_titanic_df = transform_features(X_titanic)\n",
        "\n",
        "X_titanic_df.head()"
      ],
      "metadata": {
        "id": "Kri8uth6HKXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 세트, 테스트 세트 분리\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic, test_size=0.2, random_state=11)"
      ],
      "metadata": {
        "id": "JFmvz2aJBIdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 / 예측 / 평가\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_clf = LogisticRegression(solver='liblinear', random_state=11)\n",
        "\n",
        "lr_clf.fit(X_train, y_train)\n",
        "\n",
        "pred = lr_clf.predict(X_test)\n",
        "\n",
        "get_clf_eval(y_test, pred)"
      ],
      "metadata": {
        "id": "zZypp7UzBIar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# 결정 임계값(Threshold)을 조정해서 정밀도 또는 재현율의 수치를 조정 가능하다.\n",
        " : 정밀도와 재현율의 관계는 상호 보완적 - 어느 한쪽을 높이면 다른 한쪽은 내려가는 형태\n",
        "   => 트레이드 오프(trade-off) 관계\n",
        "\n",
        "\n",
        "# 결정 임계값 : 보통 모델이 판단을 할 때 특정 값을 기준으로 하여 이 기준값 보다 크면 Positive,\n",
        "                 이 기준값 보다 작으면 Negative 라고 결정을 함.\n",
        "                 이 판단 기준이 결정임계값임.\n",
        "\n",
        "                 일반적으로 이진분류에는 0.5가 보통.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "Aj1fsLL0BIYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 현재 모델이 각 데이터에 대해 어떻게 판단하고 있는지 확인 : predict_proba()\n",
        "pred_proba = lr_clf.predict_proba(X_test)\n",
        "\n",
        "print('현재 모델의 판단 정보 : \\n', pred_proba[:3], '------', pred[:3])"
      ],
      "metadata": {
        "id": "vb6381abBIVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# 트레이드-오프 시 주의 사항\n",
        " - 결정 임계값의 변경은 업무 상황에 맞게 두 정밀도, 재현율 수치를 상호 보완하는 수준에서 적용해야 한다\n",
        " - 단순히 하나의 지표를 높이기 위해서 사용하는 것은 안된다!!\n",
        "'''"
      ],
      "metadata": {
        "id": "pknbFN0nD77I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. F-1 Score\n",
        "\n",
        "* 정밀도와 재현율을 결합한 지표\n",
        "\n",
        "* 정밀도와 재현율이 어느 한쪽으로 치우치지 않은 수치를 나타내면 F1 스코어도 상대적으로 높은 수치를 보임"
      ],
      "metadata": {
        "id": "cLx8GW8rH0D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(y_test, pred)"
      ],
      "metadata": {
        "id": "z3W01mvbD71J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. ROC Curve과 AUC\n",
        "\n",
        "* 이진 분류의 예측 성능을 평가하는 최근 지표"
      ],
      "metadata": {
        "id": "3_1rAptWI-IG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# ROC (Receiver Operation Curve) : 수신자 판단 곡선\n",
        " - FPR (False Positive Rate) 가 변할 때 TPR(재현율, 민감도) 이 어떻게 변하는 지를 나타내는 곡선\n",
        "'''"
      ],
      "metadata": {
        "id": "BJ99_2FCD7yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확도, 정밀도, 재현율, 오차행렬, f1 score, auc_score 등을 한꺼번에 구하는 함수\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "\n",
        "def get_clf_eval(y_test, pred):\n",
        "  confusion = confusion_matrix(y_test, pred)\n",
        "  accuracy = accuracy_score(y_test, pred)\n",
        "  precision = precision_score(y_test, pred)\n",
        "  recall = recall_score(y_test, pred)\n",
        "  f1 = f1_score(y_test, pred)\n",
        "  auc = roc_auc_score(y_test, pred)\n",
        "\n",
        "  print('--- 오차 행렬 -----')\n",
        "  print(confusion)\n",
        "  print('-'*40)\n",
        "  print(f'정확도 : {accuracy}, 정밀도 : {precision}, 재현율 : {recall}')\n",
        "  print(f'f1 score : {f1}, AUC : {auc}')"
      ],
      "metadata": {
        "id": "4vC_kDNtHiBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_clf_eval(y_test, pred)"
      ],
      "metadata": {
        "id": "xqMn0lNdHh-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SCeLW9wSHh8m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}