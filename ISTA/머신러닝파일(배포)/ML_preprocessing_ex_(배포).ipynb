{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리\n",
        "\n",
        "# Garbage In, Garbage Out\n",
        "\n",
        "# 사이킷런을 이용한 ML 학습하기 전에 데이터에 대해 처리할 기본사항\n",
        "\n",
        "## 1. 결손값 (NA, NaN, NULL) 값은 허용되지 않는다.\n",
        "\n",
        "    * 대체값을 선정해서 치환\n",
        "\n",
        "    * Drop\n",
        "\n",
        "## 2. 사이킷런의 머신러닝 알고리즘은 문자열을 입력값으로 받지 않는다.\n",
        "\n",
        "    * 인코딩\n",
        "\n",
        "    * Drop\n",
        "\n"
      ],
      "metadata": {
        "id": "NHvVd7OXXc8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모듈 로딩\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "WS7AhxB3dwOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결측치 (누락 데이터) 처리"
      ],
      "metadata": {
        "id": "j67ObflrdTeL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8AJFbjbW_3Z"
      },
      "outputs": [],
      "source": [
        "# 데이터 로딩\n",
        "df = sns.load_dataset('titanic')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[누락데이터 확인]**"
      ],
      "metadata": {
        "id": "CZMLSuC6hKoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 요약 정보 확인\n",
        "df.info()"
      ],
      "metadata": {
        "id": "9AqnTUGtXSpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deck 컬럼에 NaN 개수\n",
        "nan_deck = df['deck'].value_counts(dropna=False)    # value_counts : default가 NaN을 제외하고 갯수를 구하도록 설계\n",
        "nan_deck"
      ],
      "metadata": {
        "id": "eaNk1tfqXSnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# isnull() - 직접적인 방법 : 누락데이면 True, 아니면 False\n",
        "df.head().isnull()"
      ],
      "metadata": {
        "id": "GyzjMiZJXSks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# notnull() - 간접적인 방법 : 유효한 데이터면 True, 누락데이터면 False\n",
        "df.tail().notnull()"
      ],
      "metadata": {
        "id": "6U9Jr77DXSiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 직접적인 방법으로 누락데이터 갯수 구하기\n",
        "df.head().isnull().sum(axis=0)     # True : 1, False : 0으로 인정되므로 연산이 가능"
      ],
      "metadata": {
        "id": "a8nmkOZLlN7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [실습] 전체 데이터 각 컬럼의 누락데이터 갯수를 구해보세요\n"
      ],
      "metadata": {
        "id": "TtQiaa62lN4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[누락데이터 삭제]**\n",
        "\n",
        "* 컬럼이 데이터 관계상 상관관계가 별로 없고, 누락데이터가 너무 많을 경우\n",
        "\n",
        "* 이 컬럼을 삭제하는 것이 분석(예측)에 더 의미가 있다고 판단 되는 아주 특수한 경우"
      ],
      "metadata": {
        "id": "0eiNh2PdrtrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_thresh = df.dropna(axis=1, thresh=500)            # thresh : NaN 최소 기준치\n",
        "df_thresh.columns"
      ],
      "metadata": {
        "id": "U6eO58tOlN2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# age 컬럼에 나이 데이터가 없는 행을 삭제\n",
        "df_age = df.dropna(subset=['age'], how='any', axis=0)\n",
        "print(len(df_age))"
      ],
      "metadata": {
        "id": "20mCK60ZlNzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[누락 데이터 치환(대치)]**\n",
        "\n",
        "* 보통 대체할 값으로는 데이터의 분포와 특성을 잘 나타낼 수 있는 값 : 평균값, 중앙값, 최빈값 등"
      ],
      "metadata": {
        "id": "OLeON7WMuJi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Vp3KNCZertOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# age 컬럼 확인\n",
        "df.age.head(10)"
      ],
      "metadata": {
        "id": "iTSxEj5frtKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 평균값으로 대치"
      ],
      "metadata": {
        "id": "dHBDv-bMvNZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_age = df.age.mean(axis=0)\n",
        "df.age.fillna(mean_age, inplace=True)"
      ],
      "metadata": {
        "id": "A8VpiesYrtHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.age.isnull().sum(axis=0)"
      ],
      "metadata": {
        "id": "rJy3Wcv2uxBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 최빈값으로 대치"
      ],
      "metadata": {
        "id": "P-UAqYCgwcMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['embark_town'][825:835]"
      ],
      "metadata": {
        "id": "RzqLGgTnuw9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 승선도시 중에서 가장 많이 출현한 값으로 대치\n",
        "most_freq = df['embark_town'].value_counts(dropna=True).idxmax()\n",
        "\n",
        "most_freq"
      ],
      "metadata": {
        "id": "a5lQFjGIuw6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['embark_town'].fillna(most_freq, inplace=True)\n",
        "df['embark_town'][825:835]"
      ],
      "metadata": {
        "id": "K7UhYutdwgjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 이전 값으로 대치\n",
        "\n",
        "* 데이터셋의 특성 상 서로 이웃하고 있는 데이터끼리는 유사성을 가질 가능성이 높기 때문"
      ],
      "metadata": {
        "id": "W9Rtb-Wnx-e5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['embarked'][825:835]"
      ],
      "metadata": {
        "id": "e7R8Fnt3wgiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embarked 컬럼의 NaN값을 찾아서 바로 이전행 값으로 치환\n",
        "df['embarked'].fillna(method='ffill', inplace=True)\n",
        "df['embarked'][825:835]"
      ],
      "metadata": {
        "id": "Rvxdt2tKwgfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "09Eq6RFTywCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "[참고] 누락데이터가 NaN으로 표시되지 않은 경우\n",
        "예를 들어서 숫자 0 또는 문자 '-', '?', '=\" 값으로 입력되어 있는 데이터셋들이 있음.\n",
        "\n",
        "# 해결방법은 위 NaN이 아닌 기호나 숫자를 NaN으로 바꾼 후 NaN 처리 함수를 사용하면 더 생산성 높게 처리 가능.\n",
        "ex) df.replace('-', np.nan, inplace=True)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "qfYkxmDpwgdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 중복데이터 처리"
      ],
      "metadata": {
        "id": "y7BoYnYiLUT-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[중복 데이터 확인]**"
      ],
      "metadata": {
        "id": "Enco8wLfLmPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복 데이터 생성\n",
        "df = pd.DataFrame({\n",
        "    'c1' : ['a', 'a', 'b', 'a', 'b'],\n",
        "    'c2' : [1, 1, 1, 2, 2],\n",
        "    'c3' : [1, 1, 2, 2, 2]\n",
        "})\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "o26gGoA7y1Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# duplicated : 중복값이면 True / 아니면 False 반환\n",
        "\n",
        "# 전체 행에서 각 컬럼별 중복값이 모두 일치하는 행 찾기\n",
        "df_dup = df.duplicated()\n",
        "\n",
        "df_dup"
      ],
      "metadata": {
        "id": "1kkIQj5Ny1MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 특정 컬럼별 중복값 찾기\n",
        "col_dup = df.c2.duplicated()\n",
        "col_dup"
      ],
      "metadata": {
        "id": "Su-hGCqey1Jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[중복 데이터 제거]**"
      ],
      "metadata": {
        "id": "ItVwtXcHNOvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "FE1IWvkmLr_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 행에서 중복되는 행을 제거\n",
        "df2 = df.drop_duplicates()\n",
        "df2"
      ],
      "metadata": {
        "id": "IlAYUbXLLr8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 특정 컬럼을 기준으로 중복되는 행을 제거\n",
        "df3 = df.drop_duplicates(subset='c2')\n",
        "df3"
      ],
      "metadata": {
        "id": "uRb-OhR6Lr6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기준이 되는 컬럼을 여러 개 사용 가능\n",
        "df4 = df.drop_duplicates(subset=['c2', 'c3'])\n",
        "df4"
      ],
      "metadata": {
        "id": "7izQXSNDNgiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "j3-rUBucNgfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 표준화\n",
        "\n",
        "* 데이터가 잘 정리된 것 처럼 보여도 서로 다른 단위가 섞여 있거나 같은 대상을 다른 형식으로 표현하는 경우가 의외로 많다.\n",
        "\n",
        "* 동일한 대상을 표현하는 방법에 차이가 있으면 분석(예측) 정확도는 현저히 낮아진다.\n",
        "\n",
        "* 데이터 포맷을 일관성 있게 표준화 하는 작업이 필요하다.\n",
        "\n",
        "* 데이터의 출처 또는 데이터에 대한 설명이 반드시 필요!!"
      ],
      "metadata": {
        "id": "5MhRn4D4Ondm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[단위 환산]**"
      ],
      "metadata": {
        "id": "p0jrjeBhQfyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "   1.  mpg:               연비                          continuous\n",
        "    2. cylinders:         실린더수                        multi-valued discrete\n",
        "    3. displacement:      배기량                           continuous\n",
        "    4. horsepower:       마력                              continuous\n",
        "    5. weight:           차중                               continuous\n",
        "    6. acceleration:     가속                                 continuous\n",
        "    7. model year:       생산년도                        multi-valued discrete\n",
        "    8. origin:           생산지역                     multi-valued discrete (1 : USA, 2 : EU, 3 : JPN)\n",
        "    9. car name:         자동차명                    string (unique for each instance)\n",
        "'''"
      ],
      "metadata": {
        "id": "qgbHknw0Smau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_name = ['mpg','cylinders', 'displacement', 'horsepower', 'weight',\n",
        "                'acceleration', 'model year', 'origin', 'car name']"
      ],
      "metadata": {
        "id": "C4LskaS1UVKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./auto-mpg.csv', header=None)\n",
        "df.columns = feature_name\n",
        "df.head()"
      ],
      "metadata": {
        "id": "u52lFszDNgc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mpg (mile per gallon) - kpl (killometer per liter)로 변환 (mpg to kpl = 0.425)\n",
        "mpg_to_kpl = 1.60934 / 3.75841\n",
        "\n",
        "# 데이터셋에 kpl 열을 추가\n",
        "df2 = df.copy()\n",
        "\n",
        "df2['kpl'] = (df2.mpg * mpg_to_kpl)\n",
        "\n",
        "df2.head(3)"
      ],
      "metadata": {
        "id": "kNNZs7xGOmdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[자료형 변환]**"
      ],
      "metadata": {
        "id": "bdlgP3XmaB9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "E0g3e5r_OmbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df.copy()\n",
        "\n",
        "df3.head()"
      ],
      "metadata": {
        "id": "-eHL2ZndOmYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 기본 정보\n",
        "df3.info()"
      ],
      "metadata": {
        "id": "twZUVPVAOmV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# horsepower 컬럼의 고유값 확인\n",
        "df3.horsepower.unique()"
      ],
      "metadata": {
        "id": "pfbqqbLhOmQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '?' 관측값 처리 : NaN으로 바꾸고 NaN 처리\n",
        "import numpy as np\n",
        "\n",
        "df3.horsepower.replace('?', np.nan, inplace=True)\n",
        "\n",
        "df3.horsepower.unique()"
      ],
      "metadata": {
        "id": "eRWg5kZ9OmNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '?' - nan - 삭제 처리\n",
        "df3.dropna(subset='horsepower', axis=0, inplace=True)\n",
        "\n",
        "df3.horsepower.unique()"
      ],
      "metadata": {
        "id": "ImSfsvN-avnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 현재 object인 horsepower 컬럼 자료형을 수치형(실수형)으로 변환\n",
        "df3.horsepower = df3.horsepower.astype('float')\n",
        "\n",
        "df3.horsepower.dtypes"
      ],
      "metadata": {
        "id": "ikh4PcpjavkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.horsepower.unique()"
      ],
      "metadata": {
        "id": "QjoofKNqbuR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 정규화\n",
        "\n",
        "* 각 컬럼(특징, 변수)에 들어있는 숫자데이터의 상대적 크기 차이는 특정 분석(알고리즘) 방법에 따라서 분석 결과를 달라지게 할 수 있다.\n",
        "\n",
        "* 상대적 크기 차이를 제거하기 위해 데이터 값을 동일한 크기 기준으로 나누는 작업을 정규화(normalization) 이라고 한다.\n",
        "\n",
        "* 보통 정규화 과정을 거친 데이터의 범위는\n",
        "  0 ~ 1 사이 또는 -1 ~ 1 사이가 된다.\n",
        "\n",
        "----\n",
        "\n",
        "* [참고] 경우에 따라서는 특정 알고리즘이 상대적 크기 차이를 가정하고 생성되어 있다면 상대적 크기 차이를 갖도록 데이터를 제공하는 것이 더 좋은 결과를 얻을 수 있다."
      ],
      "metadata": {
        "id": "lJ5WxwtecveM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[정규화 1. 해당 컬럼의 최대값(의 절대값)으로 나누기]**"
      ],
      "metadata": {
        "id": "JXzN01NreLZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = df3.copy()"
      ],
      "metadata": {
        "id": "Yyr9g_jTfDdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기술통계\n",
        "df3.horsepower.describe()"
      ],
      "metadata": {
        "id": "8vH7ArStbuPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규화1 처리\n",
        "df3.horsepower = df3.horsepower / abs(df3.horsepower.max())\n",
        "\n",
        "df3.head()"
      ],
      "metadata": {
        "id": "ORuG6GRobuNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.horsepower.describe()"
      ],
      "metadata": {
        "id": "o9OkUAusbuKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[정규화2. 각 컬럼 데이터 중에서 최대값과 최소값을 뺀 값으로 나누는 방법]**"
      ],
      "metadata": {
        "id": "_tNfqyGdfr-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# 각 컬럼 데이터에서 해당 열의 최소값을 뺀 값을 분자,\n",
        "# 해당 열의 최대값과 최소값의 차이를 분모,\n",
        "# 가장 큰 값은 역시 1이 됨.\n",
        "'''"
      ],
      "metadata": {
        "id": "fYHvd8bHfe2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerator = df4.horsepower - df4.horsepower.min()   # 분자\n",
        "denominator = df4.horsepower.max() - df4.horsepower.min()   # 분모\n",
        "\n",
        "df4.horsepower = numerator / denominator\n",
        "\n",
        "df4.horsepower.head()"
      ],
      "metadata": {
        "id": "jdxAwmhAfezs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4.horsepower.describe()"
      ],
      "metadata": {
        "id": "YmcaeJvDfexi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 범주형(카테고리) 데이터 처리\n",
        "\n",
        "* 알고리즘에 따라서는 연속데이터를 그대로 사용하기 보다는 일정한 구간(bin)으로 나눠서 분석(학습) 하는 것이 효율적인 경우가 있음.\n",
        "\n",
        "* 가격, 비용, 효율 등의 의미를 가지고 있는 연속적인 값은 일정한 수준이나 정도를 가지고 있는 이산적인 값으로 나타내어서 수준의 차이를 드러내는 방식으로 구현하면 더 효율적인 경우가 있다\n",
        "\n",
        "* 이런 과정을 구간 분할 (binning)이라고 함.\n",
        "\n",
        "      pandas : cut()"
      ],
      "metadata": {
        "id": "3QzHQyIHmNgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[구간 분할]**"
      ],
      "metadata": {
        "id": "rVwhJJA_nOu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.copy()"
      ],
      "metadata": {
        "id": "0S3JbipGoDWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.horsepower.replace('?', np.nan, inplace=True)\n",
        "df2.dropna(subset='horsepower', axis=0, inplace=True)\n",
        "df2.horsepower = df2.horsepower.astype('float')\n",
        "df2.horsepower.unique()"
      ],
      "metadata": {
        "id": "Ls_h63_wfeu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "UI03KEi-pKCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3개의 구간으로 나누어서 표기\n",
        "# np.histogram()\n",
        "\n",
        "count, bin_dividers = np.histogram(df2.horsepower, bins=3)\n",
        "\n",
        "print(count)        # 구간별 데이터의 수\n",
        "print('-'*50)\n",
        "print(bin_dividers)    # 구간의 경계값들"
      ],
      "metadata": {
        "id": "sGnDioRqf1L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 나눠지는 경계로 구간명을 지정\n",
        "bin_names = ['저출력', '보통출력', '고출력']"
      ],
      "metadata": {
        "id": "d3zK-qOJodyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 데이터를 각 구간에 할당 처리\n",
        "df2['hp_bins'] = pd.cut(x=df2['horsepower'],     # 원 데이터 배열\n",
        "                        bins = bin_dividers,          # 경계 값 리스트\n",
        "                        labels=bin_names,             # 구간의 이름\n",
        "                        include_lowest=True          # 첫 경계값 포함 여부\n",
        "                        )\n",
        "\n",
        "df2[['horsepower', 'hp_bins']].head(15)"
      ],
      "metadata": {
        "id": "6zr5LlgSodwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 데이터 확인\n",
        "df2.head(10)"
      ],
      "metadata": {
        "id": "vX_o0QKuodt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[더미 변수]**\n",
        "\n",
        "* 위 hp_bins 범주형데이터는 문자열이므로 컴퓨터(모델)이 인식할 수 없는 형태\n",
        "\n",
        "* 특정 알고리즘은 더 높은 숫자값에 가중치를 부여하는 경우가 있으므로 주의가 필요.\n",
        "\n",
        "* pandas는 더미변수(숫자 0 또는 1로 표현하는 값) 라는 것을 이용.\n",
        "\n",
        "* 어떤 특성이 있는지 여부만 표현. 특성이 있으면 1, 없으면 0.\n",
        "\n",
        "* 이 개념을 머신러닝에서는 one-hot encoding\n",
        "\n",
        "\n",
        "        pandas : get_dummis()\n",
        "\n"
      ],
      "metadata": {
        "id": "567MWmJRsAhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hp_bins 컬럼(범주형 데이터)를 더미 변수로 변환\n",
        "horsepower_dummies = pd.get_dummies(df2['hp_bins'], dtype='int')\n",
        "\n",
        "horsepower_dummies.head(15)"
      ],
      "metadata": {
        "id": "xLgj4rCiqtZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.__version__"
      ],
      "metadata": {
        "id": "yP33oDOTqtXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "obQN8PBriB_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 인코딩\n",
        "\n",
        "### **[레이블 인코딩]**\n",
        "\n",
        "* 카테고리 피처를 코드형 숫자값으로 변환하는 방식"
      ],
      "metadata": {
        "id": "jIZs9fkdletb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "items = ['TV', '냉장고', '전자렌지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']"
      ],
      "metadata": {
        "id": "M9O5WKr6qtVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encoder 객체를 생성, fit() - transform() 으로 label encoding 수행\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "encoder.fit(items)\n",
        "\n",
        "labels = encoder.transform(items)\n",
        "\n",
        "print('인코딩 변환갑 : ', labels)"
      ],
      "metadata": {
        "id": "omXRqLQfqtTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('인코딩 클래스 : ', encoder.classes_)\n",
        "\n",
        "#items = ['TV', '냉장고', '전자렌지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']"
      ],
      "metadata": {
        "id": "f9ltjKyLqtRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 정보를 가지고 있으므로 디코딩 가능\n",
        "print('디코딩 클래스 : ', encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3]))"
      ],
      "metadata": {
        "id": "E_KoHqtkmKNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "[주의]\n",
        "# 레이블 인코딩은 labeldl 숫자(정수)가 1씩 증가되는 형태로 변환되는 특성이 있음\n",
        "# 연속형 숫자로 이뤄지는 특성에 영향을 받는 모델일 경우에는 label encoding이 문제가 될 수 있다.\n",
        "\n",
        "# => one-hot encoding\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "PAX5951FmKKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[원-핫(one-hot) 인코딩]**\n",
        "\n",
        "* 고유값에만 해당하는 컬럼에만 1을 표시하고 나머지는 0을 표시하는 방식\n",
        "\n",
        "* 유의사항\n",
        "\n",
        "  1. 모든 문자열의 값은 숫자형 값이어야 한다.\n",
        "\n",
        "  2. 입력값으로 2차원의 데이터이어야 한다."
      ],
      "metadata": {
        "id": "ohx1FJ5Vo5YT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "items = ['TV', '냉장고', '전자렌지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
        "\n",
        "# 숫자값 변환을 위해 LabelEncoder로 변환이 먼저\n",
        "encoder = LabelEncoder()\n",
        "labels = encoder.fit_transform(items)\n",
        "print(f'인코딩 변환값 : {labels}')"
      ],
      "metadata": {
        "id": "WgqstSVcmKIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코딩 변환값을 2차원 데이터로 변환\n",
        "labels = labels.reshape(-1, 1)\n",
        "labels"
      ],
      "metadata": {
        "id": "zHzgn2_goVvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원-핫 인코딩을 적용\n",
        "oh_encoder = OneHotEncoder()\n",
        "oh_encoder.fit(labels)\n",
        "oh_labels = oh_encoder.transform(labels)\n",
        "\n",
        "print('------- 원 - 핫 인코딩 관측값 -------')\n",
        "print(oh_labels.toarray())\n",
        "print(f'원-핫 인코딩 데이터 차원 : ', oh_labels.shape)"
      ],
      "metadata": {
        "id": "Ox1tC64hoVsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 같은 결과를 pandas로 얻어낼 수 있음\n",
        "\n",
        "df = pd.DataFrame({'items': ['TV', '냉장고', '전자렌지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "DJM4J01QoVqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.get_dummies(df, dtype='int')"
      ],
      "metadata": {
        "id": "aCMRBksHrLne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 피처스케일링(Feature Scaling)\n",
        "\n",
        "* 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업\n",
        "\n",
        "    * 피처스케일링의 대표적 방법 : 표준화(Standardization), 정규화(Normalization)"
      ],
      "metadata": {
        "id": "7NmL5SpysgR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# 표준화 : 데이텟의 피처 각각이 평균이 0이고 분산이 1인 가우시안 정규분포를 가진 값으로 변환하는 것.\n",
        "# 정규화 : 서로 다른 피처 크기를 통일시키기 위해 그 크기를 변환해주는 것\n",
        "\n",
        "# => 사이킷런은 이런 작업을 통칭해서 피처스케일링\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "H-UhBx0frLlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[StandardScaler]**"
      ],
      "metadata": {
        "id": "BvorPML2uTQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "iris_df.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SLRoMOYCrLiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('--- feature 들의 평균값 ----')\n",
        "print(iris_df.mean())\n",
        "print('--- feauter 들의 분산값 ----')\n",
        "print(iris_df.var())"
      ],
      "metadata": {
        "id": "H53vrGg0tBhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 객체 생성\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 데이터셋 변환 : fit(), transform()\n",
        "scaler.fit(iris_df)\n",
        "\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "iris_scaled"
      ],
      "metadata": {
        "id": "A5Eul8fStBe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 피처스케일링 결과과 ndarray 객체로 리턴된다\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "\n",
        "print('--- feature 들의 평균값 ----')\n",
        "print(iris_df_scaled.mean())\n",
        "print('--- feauter 들의 분산값 ----')\n",
        "print(iris_df_scaled.var())"
      ],
      "metadata": {
        "id": "XyEZ94HjtBcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[MinMaxScaler]**\n",
        "\n",
        "* 데이터 값을 0과 1사이의 범위 값으로 변환 (음수값이 있으면 -1부터 1값으로 변환)\n",
        "\n",
        "* 데이터 분포가 가우시안 분포가 아닐 경우에 적용해 볼 수 있음."
      ],
      "metadata": {
        "id": "w32cJC151gyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# 객체 생성\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# fit(), transform()\n",
        "scaler.fit(iris_df)\n",
        "\n",
        "iris_scaled = scaler.transform(iris_df)"
      ],
      "metadata": {
        "id": "_ezQ69bWtBZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 피처스케일링 결과과 ndarray 객체로 리턴된다\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "\n",
        "print('--- feature 들의 최소값 ----')\n",
        "print(iris_df_scaled.min())\n",
        "print('--- feauter 들의 최대값 ----')\n",
        "print(iris_df_scaled.max())"
      ],
      "metadata": {
        "id": "mLzdNZmQwxIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[유의사항]**\n",
        "\n",
        "* Scaler를 이용해서 학습데이터와 테스트데이터에 fit(), transform(), fit_transform() 적용시\n",
        "\n",
        "* 학습데이터로 fit()을 수행한 스케일링 기준 정보를 그대로 테스트 데이터에 적용해야 한다.\n"
      ],
      "metadata": {
        "id": "LZQRWW6L2v3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문제 상황\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "okHXH-wBwxGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습데이터는 0~10까지, 테스트데이터 : 0~5 값을 갖는 데이터 세트\n",
        "# fit(), transform() 2차원 이상의 데이터 형태만 가능함\n",
        "train_array = np.arange(0, 11).reshape(-1, 1)\n",
        "test_array = np.arange(0, 6).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "B47puAjnwxDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 피처 스케일링 (train data) 적용\n",
        "\n",
        "# 객체 호출\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# fit() - 기준 적용 (최소값을 0, 최대값을 10으로 설정)\n",
        "scaler.fit(train_array)\n",
        "\n",
        "# transform() - 1/10 scale 적용\n",
        "train_scaled = scaler.transform(train_array)\n",
        "\n",
        "# 데이터 확인\n",
        "print('원본 train_array 데이터 값 : ', np.round(train_array.reshape(-1), 2))\n",
        "print('scaled 된 train_array 데이터 값 : ', np.round(train_scaled.reshape(-1), 2))"
      ],
      "metadata": {
        "id": "Vu9K4YJ82uiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 피처 스케일링 (test data) 적용\n",
        "\n",
        "# 객체 호출\n",
        "# fit()   - 기준 (최소값을 0, 최대값을 5)  => 새로운 기준 정보가 생성되었다.\n",
        "scaler.fit(test_array)\n",
        "\n",
        "# transform - 1/5 scale\n",
        "test_scaled = scaler.transform(test_array)\n",
        "\n",
        "# 데이터 확인\n",
        "print('원본 test_array 데이터 값 : ', np.round(test_array.reshape(-1), 2))\n",
        "print('scaled 된 test_array 데이터 값 : ', np.round(test_scaled.reshape(-1), 2))"
      ],
      "metadata": {
        "id": "P7aog7kQ2ugI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 올바른 방법\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# fit() - 기준 적용 (최소값을 0, 최대값을 10으로 설정)\n",
        "scaler.fit(train_array)\n",
        "\n",
        "# transform() - 1/10 scale 적용\n",
        "train_scaled = scaler.transform(train_array)\n",
        "\n",
        "# 데이터 확인\n",
        "print('원본 train_array 데이터 값 : ', np.round(train_array.reshape(-1), 2))\n",
        "print('scaled 된 train_array 데이터 값 : ', np.round(train_scaled.reshape(-1), 2))\n",
        "\n",
        "# 테스트 데이터의 scale 변환은 fit() 호출없이 train 데이터의 기준을 적용해서 바로 transform()만 수행\n",
        "test_scaled = scaler.transform(test_array)\n",
        "\n",
        "# 데이터 확인\n",
        "print('원본 test_array 데이터 값 : ', np.round(test_array.reshape(-1), 2))\n",
        "print('scaled 된 test_array 데이터 값 : ', np.round(test_scaled.reshape(-1), 2))"
      ],
      "metadata": {
        "id": "iFYsGjus2ubZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jhXBKMGO2uZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ij3PsOit2uWd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}