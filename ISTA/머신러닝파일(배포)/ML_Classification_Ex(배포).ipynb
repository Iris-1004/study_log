{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 분류 (Classification)"
      ],
      "metadata": {
        "id": "tjGSi6eABgw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "Y1fWODzdBeNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 처리 함수\n",
        "def fillna_nan(df):\n",
        "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "  df['Cabin'].fillna('N', inplace=True)\n",
        "  df['Embarked'].fillna('N', inplace=True)\n",
        "  return df\n",
        "\n",
        "# 레이블 인코딩\n",
        "def label_encoding_features(df):\n",
        "  features = ['Sex', 'Embarked']\n",
        "  for feature in features :\n",
        "    encoder = LabelEncoder()\n",
        "    df[feature] = encoder.fit_transform(df[feature])\n",
        "  return df\n",
        "\n",
        "# 모델에게 불필요한 특성(feature) 제거\n",
        "def drop_feature(df):\n",
        "  df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
        "  return df\n",
        "\n",
        "# 최종적으로 전처리를 수행할 함수\n",
        "def transform_features(df):\n",
        "  df = fillna_nan(df)\n",
        "  df = drop_feature(df)\n",
        "  df = label_encoding_features(df)\n",
        "  return df"
      ],
      "metadata": {
        "id": "GsdzEmZXBeIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로딩\n",
        "titanic_df = pd.read_csv('./titanic_train.csv')\n",
        "\n",
        "# target (label) 데이터\n",
        "y_titanic = titanic_df['Survived']\n",
        "\n",
        "# feature 데이터\n",
        "X_titanic = titanic_df.drop('Survived', axis=1)\n",
        "\n",
        "# feature 전처리\n",
        "X_titanic_df = transform_features(X_titanic)\n",
        "\n",
        "X_titanic_df.head()"
      ],
      "metadata": {
        "id": "u8_6KQ7mBeGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_titanic_df.info()"
      ],
      "metadata": {
        "id": "2Bl2PtnPGgKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN 알고리즘"
      ],
      "metadata": {
        "id": "MEw13WvCYKDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# KNN (K-Nearest-Neighbors) : K 개의 가까운 이웃\n",
        " - 새로운 데이터가 주어지면 기존의 데이터 중에서 가장 속성이 비슷한 K개의 이웃을 먼저 찾음.\n",
        " - 가까운 이웃들이 갖고 있는 목표값과 같은 값으로 분류하여 예측하는 알고리즘\n",
        " - 이 K값에 따라 예측의 정확도가 달라지므로, 적절한 K값을 찾는 것이 관건\n",
        "'''"
      ],
      "metadata": {
        "id": "SqZ85ouxX4Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 세트, 테스트 세트 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic, test_size=0.2, random_state=11)"
      ],
      "metadata": {
        "id": "G4oxUKDOBeEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습(KNN) / 예측 / 평가\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# 객체 생성\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# 학습\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# 예측 (분류)\n",
        "pred = knn.predict(X_test)\n",
        "\n",
        "print(pred[0:10])\n",
        "print('-'*40)\n",
        "print(y_test.values[0:10])"
      ],
      "metadata": {
        "id": "zafPnL30X4OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "knn_matrix = confusion_matrix(y_test, pred)\n",
        "knn_matrix"
      ],
      "metadata": {
        "id": "EineLD2gGXPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가지표\n",
        "from sklearn.metrics import classification_report\n",
        "knn_report = classification_report(y_test, pred)\n",
        "\n",
        "print(knn_report)"
      ],
      "metadata": {
        "id": "s_o4L1qHX4Lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM 알고리즘"
      ],
      "metadata": {
        "id": "HZbHUM40doNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_model = SVC(kernel='rbf')\n",
        "\n",
        "# kernel : 데이터를 벡터 공간으로 매핑하는 함수\n",
        "#  - rbf(radial basic function), Linear, Polynimal, Sigmoid\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "pred = svm_model.predict(X_test)"
      ],
      "metadata": {
        "id": "fEw8JkmHX4JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가\n",
        "svm_matrix = confusion_matrix(y_test, pred)\n",
        "print(svm_matrix)\n",
        "print('-'*40)\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "iGM5SJxvX4Gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree 알고리즘"
      ],
      "metadata": {
        "id": "A9k8KneQfB4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# 결정 트리 (의사 결정 나무)\n",
        "# 자료구조 중 트리 구조를 사용하고, 각 분기점(node)에 분석 대상의 속성(독립변수)를 위치.\n",
        "# 각 분기점마다 목표값을 가장 잘 분류할 수 있는 속성을 찾아서 배치하고,\n",
        "  해당 속성이 갖는 값을 이용하여 새로운 가지(brach)를 만들어 가는 방식\n",
        "\n",
        "# 결정트리 성능을 결정하는 것은 균일한 세트가 필요\n",
        "# 균일도를 측정하는 대표적인 방법\n",
        " - 엔트로피\n",
        " - 지니계수\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "n3HriC81X4EC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree_model = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
        "# 정확해지려면 max_depth가 많으면 된다. 그러나 너무 깊어지면 과대적합이 일어날 수 있음에 유의\n",
        "# 적절한 깊이, 가지 수 등을 찾는 것이 중요\n",
        "\n",
        "tree_model.fit(X_train, y_train)\n",
        "\n",
        "pred = tree_model.predict(X_test)"
      ],
      "metadata": {
        "id": "xA1GFDsafBWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test, pred))\n",
        "print('-'*40)\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "Ke1HCUDxfBTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[결정 트리 모델 시각화]**"
      ],
      "metadata": {
        "id": "lHl8IiiFh_Ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
        "                                                    test_size=0.2, random_state=11)\n",
        "\n",
        "dt_clf = DecisionTreeClassifier(random_state=11)\n",
        "\n",
        "dt_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "lHpHcfLufBRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# graphviz pydot"
      ],
      "metadata": {
        "id": "KvMteTcTfBOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "export_graphviz(dt_clf, out_file='tree.dot', class_names=iris_data.target_names,\n",
        "                feature_names=iris_data.feature_names, impurity=True, filled=True)"
      ],
      "metadata": {
        "id": "c3txelvifBMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# out_file을 읽어들여서 notebook 화면에 시각화\n",
        "import graphviz\n",
        "\n",
        "with open('tree.dot') as f:\n",
        "  dot_graph = f.read()\n",
        "\n",
        "graphviz.Source(dot_graph)"
      ],
      "metadata": {
        "id": "65ngVCb_fBJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 랜덤포레스트 알고리즘"
      ],
      "metadata": {
        "id": "8OOdb1NxlDqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "iris_data = load_iris()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
        "                                                    test_size=0.2, random_state=11)\n",
        "\n",
        "rf_clf = RandomForestClassifier(random_state=11)\n",
        "\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "pred = rf_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "e_iKPYx1jAAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "5Z_Q3B3vi_-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble"
      ],
      "metadata": {
        "id": "MUlgzEcttdhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm\n",
        "\n",
        "print(lightgbm.__version__)"
      ],
      "metadata": {
        "id": "cmW4Sjfji_8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LightGBM 적용 – 위스콘신 Breast Cancer Prediction"
      ],
      "metadata": {
        "id": "O8GILkdhwOE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM의 파이썬 패키지인 lightgbm에서 LGBMClassifier 임포트\n",
        "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 로딩\n",
        "dataset = load_breast_cancer()\n",
        "cancer_df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)\n",
        "cancer_df['target'] = dataset.target\n",
        "X_features = cancer_df.iloc[:, :-1]\n",
        "y_label = cancer_df.iloc[:, -1]\n",
        "\n",
        "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, test_size=0.2, random_state=156)\n",
        "\n",
        "# 학습 데이터 중 90%는 학습용, 10%는 검증용으로 분리\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=156)\n",
        "\n",
        "# LGBMClassifier 설정\n",
        "lgbm_wrapper = LGBMClassifier(n_estimators=400, learning_rate=0.05)\n",
        "\n",
        "# 조기 종료를 위한 평가 셋\n",
        "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
        "\n",
        "# 모델 학습 (early_stopping_rounds → callbacks 로 수정)\n",
        "lgbm_wrapper.fit(\n",
        "    X_tr, y_tr,\n",
        "    eval_set=evals,\n",
        "    eval_metric=\"logloss\",\n",
        "    callbacks=[\n",
        "    early_stopping(stopping_rounds=50),\n",
        "    log_evaluation(period=10)  # 10번마다 출력\n",
        "    ],\n",
        ")\n",
        "\n",
        "# 예측\n",
        "preds = lgbm_wrapper.predict(X_test)\n",
        "pred_proba = lgbm_wrapper.predict_proba(X_test)[:, 1]\n"
      ],
      "metadata": {
        "id": "uqbuNtQRi_6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "\n",
        "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
        "    confusion = confusion_matrix( y_test, pred)\n",
        "    accuracy = accuracy_score(y_test , pred)\n",
        "    precision = precision_score(y_test , pred)\n",
        "    recall = recall_score(y_test , pred)\n",
        "    f1 = f1_score(y_test,pred)\n",
        "    # ROC-AUC 추가\n",
        "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
        "    print('오차 행렬')\n",
        "    print(confusion)\n",
        "    # ROC-AUC print 추가\n",
        "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
        "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
      ],
      "metadata": {
        "id": "0i52epAIwMlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_clf_eval(y_test, preds, pred_proba)"
      ],
      "metadata": {
        "id": "ykkZnznQwMjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_importance( )를 이용하여 feature 중요도 시각화\n",
        "from lightgbm import plot_importance\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 12))\n",
        "plot_importance(lgbm_wrapper, ax=ax)\n",
        "plt.savefig('lightgbm_feature_importance.tif', format='tif', dpi=300, bbox_inches='tight')"
      ],
      "metadata": {
        "id": "l16Yc8wmwMgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OxmAz1g5wMeY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}